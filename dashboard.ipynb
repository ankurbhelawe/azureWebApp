{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicate Logic Solution\n",
    "\n",
    "Enter Premises and a Query in the boxes below.\n",
    "____________________________________________________________\n",
    "\n",
    "Sample Premises: All living things are plants or animals. Rama's dog is a living thing. Rama's dog is not a plant. All animals have a heart.\n",
    "\n",
    "Sample Query: Rama's dog has a heart.\n",
    "\n",
    "Output: Query is TRUE.\n",
    "____________________________________________________________\n",
    "\n",
    "Sample Premises: All boys are humans. Some humans are good.\n",
    "\n",
    "Sample Query: Some boys are good.\n",
    "\n",
    "Output: Query is TRUE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from ipywidgets import *\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPremise(query):\n",
    "    q=nlp(query)\n",
    "    q_sub=\"\"\n",
    "    q_pos=True\n",
    "    q_pred=\"\"\n",
    "    q_quant=\"\"\n",
    "    q_whoThat=False\n",
    "    q_verb=\"\"\n",
    "    for token in q:\n",
    "        if token.lemma_ in [\"all\",\"every\",\"everyone\",\"each\",\"everything\"]:\n",
    "            q_quant=\"Universal\"\n",
    "        if token.lemma_ in [\"some\",\"atleast\",\"someone\"]:\n",
    "            q_quant=\"Existential\"\n",
    "        if token.lemma_ in [\"who\",\"that\"]:\n",
    "            q_whoThat=True\n",
    "        if token.dep_==\"relcl\" and q_whoThat==True:\n",
    "            q_sub+=token.lemma_\n",
    "        if token.dep_==\"dobj\" and q_whoThat==True:\n",
    "            q_sub+=\" \"+token.lemma_\n",
    "        if token.dep_==\"advmod\" and q_whoThat==True:\n",
    "            q_sub+=\" \"+token.lemma_\n",
    "        if token.dep_==\"nsubj\" and not (token.lemma_ in [\"someone\",\"something\",\"everyone\",\"everything\",\"who\",\"that\"]):\n",
    "            subject_compound=\"\"\n",
    "            for child in token.children:\n",
    "                if child.dep_==\"compound\":\n",
    "                    subject_compound+=child.lemma_+\" \"\n",
    "                if child.dep_==\"amod\":\n",
    "                        subject_compound+=child.lemma_+\" \"\n",
    "                if child.dep_==\"poss\":\n",
    "                    subject_compound+=child.lemma_+\" \"\n",
    "            subject_compound+=token.lemma_\n",
    "            q_sub=subject_compound\n",
    "        if token.dep_==\"acomp\":\n",
    "                q_pred=token.lemma_\n",
    "        if token.dep_==\"ROOT\":\n",
    "            if token.pos_==\"NOUN\":\n",
    "                q_pred+=token.lemma_+\" \"\n",
    "            if token.pos_==\"VERB\":\n",
    "                q_pred+=token.lemma_+\" \"\n",
    "                q_verb=token.lemma_+\" \"\n",
    "            for child in token.children:\n",
    "                if child.dep_==\"dobj\":\n",
    "                    q_pred+=child.lemma_+\" \"\n",
    "                if child.dep_==\"attr\":\n",
    "                    subject_compound=\"\"\n",
    "                    for child2 in child.children:\n",
    "                        if child2.dep_==\"compound\":\n",
    "                            subject_compound+=child2.lemma_+\" \"\n",
    "                        if child2.dep_==\"amod\":\n",
    "                                subject_compound+=child2.lemma_+\" \"\n",
    "                        if child2.dep_==\"poss\":\n",
    "                            subject_compound+=child2.lemma_+\" \"\n",
    "                    subject_compound+=child.lemma_\n",
    "                    q_pred=subject_compound\n",
    "                if child.dep_==\"advmod\":\n",
    "                    q_pred+=child.lemma_\n",
    "\n",
    "        if token.lemma_==\"no\" or token.dep_==\"neg\":\n",
    "            q_pos=False\n",
    "    return q_quant.strip(), q_sub.lower().strip(), q_pos, q_pred.lower().strip(), q_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solvePred(premise,query):\n",
    "    if premise==\"\" or query==\"\":\n",
    "        return(\"Empty Premise or Query! Try again.\")\n",
    "    quantifier=[]\n",
    "    subject=[]\n",
    "    positive=[]\n",
    "    predicate=[]\n",
    "    conjugation=[]\n",
    "    predicate2=[]\n",
    "    verb=[]\n",
    "    doc=nlp(premise)\n",
    "    \n",
    "    sentences=[]\n",
    "    for sent in doc.sents:\n",
    "        sentences.append(sent.text)\n",
    "    for sent in sentences:\n",
    "        sentence=nlp(sent)\n",
    "        quant=\"\"\n",
    "        sub=\"\"\n",
    "        pos=True\n",
    "        pred=\"\"\n",
    "        conj=\"\"\n",
    "        pred2=\"\"\n",
    "        sent_verb=\"\"\n",
    "        whoThat=False\n",
    "        for token in sentence:\n",
    "            if token.lemma_ in [\"who\", \"that\"]:\n",
    "                whoThat=True\n",
    "            if token.lemma_ in [\"all\",\"every\",\"everyone\",\"each\",\"everything\"]:\n",
    "                quant=\"Universal\"\n",
    "            if token.lemma_ in [\"some\",\"atleast\",\"someone\"]:\n",
    "                quant=\"Existential\"\n",
    "            if token.lemma_ == \"or\":\n",
    "                conj=token.lemma_\n",
    "            if token.dep_==\"conj\" and conj==\"or\":\n",
    "                pred2=sent_verb+token.lemma_\n",
    "            if token.lemma_ ==\"and\":\n",
    "                conj=token.lemma_\n",
    "                andindex=sent.find(\" and \")\n",
    "                pred2=sent[andindex+5:]\n",
    "                break\n",
    "            if token.dep_==\"relcl\" and whoThat==True:\n",
    "                sub+=token.lemma_\n",
    "            if token.dep_==\"dobj\" and whoThat==True:\n",
    "                sub+=\" \"+token.lemma_\n",
    "            if token.dep_==\"advmod\" and whoThat==True:\n",
    "                sub+=\" \"+token.lemma_\n",
    "            if token.dep_==\"nsubj\" and not (token.lemma_ in [\"someone\",\"something\",\"everyone\",\"everything\",\"who\",\"that\"]):\n",
    "                subject_compound=\"\"\n",
    "                for child in token.children:\n",
    "                    if child.dep_==\"compound\":\n",
    "                        subject_compound+=child.lemma_+\" \"\n",
    "                    if child.dep_==\"amod\":\n",
    "                        subject_compound+=child.lemma_+\" \"\n",
    "                    if child.dep_==\"poss\":\n",
    "                        subject_compound+=child.lemma_+\" \"\n",
    "                subject_compound+=token.lemma_\n",
    "                sub=subject_compound\n",
    "            if token.dep_==\"acomp\":\n",
    "                pred=token.lemma_\n",
    "            if token.dep_==\"ROOT\":\n",
    "                if token.pos_==\"VERB\":\n",
    "                    pred+=token.lemma_+\" \"\n",
    "                    sent_verb=token.lemma_+\" \"\n",
    "                for child in token.children:\n",
    "                    if child.dep_==\"dobj\":\n",
    "                        pred+=child.lemma_+\" \"\n",
    "                    if child.dep_==\"attr\":\n",
    "                        subject_compound=\"\"\n",
    "                        for child2 in child.children:\n",
    "                            if child2.dep_==\"compound\":\n",
    "                                subject_compound+=child2.lemma_+\" \"\n",
    "                            if child2.dep_==\"amod\":\n",
    "                                subject_compound+=child2.lemma_+\" \"\n",
    "                            if child2.dep_==\"poss\":\n",
    "                                subject_compound+=child2.lemma_+\" \"\n",
    "                        subject_compound+=child.lemma_\n",
    "                        pred=subject_compound\n",
    "                    if child.dep_==\"advmod\":\n",
    "                        pred+=child.lemma_\n",
    "\n",
    "            if token.lemma_==\"no\" or token.dep_==\"neg\":\n",
    "                pos=False\n",
    "        quantifier.append(quant.strip())\n",
    "        subject.append(sub.lower().strip())\n",
    "        positive.append(pos)\n",
    "        predicate.append(pred.lower().strip())\n",
    "        conjugation.append(conj.lower().strip())\n",
    "        predicate2.append(pred2.lower().strip())\n",
    "        verb.append(sent_verb)\n",
    "        \n",
    "    data = {'Quantifier':quantifier,\n",
    "        'Subject':subject,\n",
    "       'Positive':positive,\n",
    "       'Predicate':predicate,\n",
    "       'And/Or':conjugation,\n",
    "       'Second Predicate':predicate2}\n",
    " \n",
    "    # Create knowledge Base\n",
    "    knowledgeBase = pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "    ## Resolving AND\n",
    "    \n",
    "    for i in range (len(conjugation)):\n",
    "        if conjugation[i]==\"and\":\n",
    "            conjugation[i]=\"\"\n",
    "            q_quant_new, q_sub_new, q_pos_new, q_pred_new, q_verb_new = extractPremise(predicate2[i])\n",
    "            predicate2[i]=\"\"\n",
    "            if(q_sub_new==\"\"): #if only phrase is there after and\n",
    "                subject.append(subject[i])\n",
    "                positive.append(q_pos_new)\n",
    "                predicate.append(verb[i]+q_pred_new)\n",
    "                quantifier.append(quantifier[i])\n",
    "                conjugation.append(\"\")\n",
    "                predicate2.append(\"\")\n",
    "                verb.append(verb[i])\n",
    "            else: #if independent sentence after and\n",
    "                subject.append(q_sub_new)\n",
    "                positive.append(q_pos_new)\n",
    "                predicate.append(q_pred_new)\n",
    "                quantifier.append(q_quant_new)\n",
    "                conjugation.append(\"\")\n",
    "                predicate2.append(\"\")\n",
    "                verb.append(q_verb_new)\n",
    "            \n",
    "    \n",
    "    data = {'Quantifier':quantifier,\n",
    "        'Subject':subject,\n",
    "       'Positive':positive,\n",
    "       'Predicate':predicate,\n",
    "        'And/Or':conjugation,\n",
    "       'Second Predicate':predicate2}\n",
    "    \n",
    "    # Create knowledge Base\n",
    "    ANDResolvedKnowledgeBase = pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "    # Extending Knowledge Base\n",
    "    for i in range (len(predicate)):\n",
    "        for j in range (len(subject)):\n",
    "            # Modus Ponens\n",
    "            if predicate[i]==subject[j]:#add ignore case\n",
    "                subject.append(subject[i])\n",
    "                positive.append((positive[i] and positive[j]))\n",
    "                predicate.append(predicate[j])\n",
    "                conjugation.append(conjugation[j])\n",
    "                predicate2.append(predicate2[j])\n",
    "                if(quantifier[i]==\"Universal\"==quantifier[j]):\n",
    "                    quantifier.append(\"Universal\")\n",
    "                elif(quantifier[i]==\"Existential\"==quantifier[j]):\n",
    "                    quantifier.append(\"Existential\")\n",
    "                elif((quantifier[i]==\"Universal\" and quantifier[j]==\"Existential\") or (quantifier[j]==\"Universal\" and quantifier[i]==\"Existential\")):\n",
    "                    quantifier.append(\"Existential\")\n",
    "                else:\n",
    "                    quantifier.append(\"\")\n",
    "            # Modus Tollens\n",
    "            if predicate[i]==predicate[j]:\n",
    "                if conjugation[i]==conjugation[j]==\"\":\n",
    "                    if positive[i] == True and positive[j] == False:\n",
    "                        subject.append(subject[j])\n",
    "                        positive.append(False)\n",
    "                        predicate.append(subject[i])\n",
    "                        conjugation.append(\"\")\n",
    "                        predicate2.append(\"\")\n",
    "                        if(quantifier[i]==\"Universal\"==quantifier[j]):\n",
    "                            quantifier.append(\"Universal\")\n",
    "                        elif(quantifier[i]==\"Existential\"==quantifier[j]):\n",
    "                            quantifier.append(\"Existential\")\n",
    "                        elif((quantifier[i]==\"Universal\" and quantifier[j]==\"Existential\") or (quantifier[j]==\"Universal\" and quantifier[i]==\"Existential\")):\n",
    "                            quantifier.append(\"Existential\")\n",
    "                        else:\n",
    "                            quantifier.append(\"\")\n",
    "                \n",
    "    data = {'Quantifier':quantifier,\n",
    "        'Subject':subject,\n",
    "       'Positive':positive,\n",
    "       'Predicate':predicate,\n",
    "        'And/Or':conjugation,\n",
    "       'Second Predicate':predicate2}\n",
    " \n",
    "    # Create knowledge Base\n",
    "    extendedKnowledgeBase = pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "    # Resolving OR in Knowledge Base\n",
    "    for i in range (len(predicate)):\n",
    "        for j in range (len(subject)):\n",
    "            if subject[i]==subject[j]:\n",
    "                if predicate[i]==predicate[j] or predicate[i]==predicate2[j]:\n",
    "                    if conjugation[j]==\"or\":\n",
    "                        if(positive[i]==True and positive[j]==False):\n",
    "                            print()\n",
    "                            print(\"Inconsistent premises:\\n\")\n",
    "                            print(subject[i],positive[i],predicate[i])\n",
    "                            print(subject[j],positive[j],predicate[j], conjugation[j], predicate2[j])\n",
    "                        elif(positive[j]==True and positive[i]==False):\n",
    "                            subject.append(subject[i])\n",
    "                            positive.append(True)\n",
    "                            conjugation.append(\"\")\n",
    "                            predicate2.append(\"\")\n",
    "                            if predicate[i]==predicate[j]:\n",
    "                                predicate.append(predicate2[j])\n",
    "                            else:\n",
    "                                predicate.append(predicate[j])\n",
    "                            if(quantifier[i]==\"Universal\"==quantifier[j]):\n",
    "                                quantifier.append(\"Universal\")\n",
    "                            elif(quantifier[i]==\"Existential\"==quantifier[j]):\n",
    "                                quantifier.append(\"Existential\")\n",
    "                            elif((quantifier[i]==\"Universal\" and quantifier[j]==\"Existential\") or (quantifier[j]==\"Universal\" and quantifier[i]==\"Existential\")):\n",
    "                                quantifier.append(\"Existential\")\n",
    "                            else:\n",
    "                                quantifier.append(\"\")\n",
    "\n",
    "    data = {'Quantifier':quantifier,\n",
    "        'Subject':subject,\n",
    "       'Positive':positive,\n",
    "       'Predicate':predicate,\n",
    "        'And/Or':conjugation,\n",
    "       'Second Predicate':predicate2}\n",
    " \n",
    "    # Create knowledge Base\n",
    "    extendedKnowledgeBase = pd.DataFrame(data)\n",
    "\n",
    "    # Print the output.\n",
    "    print(\"\\n OR Resolved Knowledge Base:\")\n",
    "    print(extendedKnowledgeBase)\n",
    "    \n",
    "    # Extending OR Resolved Knowledge Base\n",
    "    for i in range (len(predicate)):\n",
    "        for j in range (len(subject)):\n",
    "            # Modus Ponens\n",
    "            if predicate[i]==subject[j]:\n",
    "                subject.append(subject[i])\n",
    "                positive.append((positive[i] and positive[j]))\n",
    "                predicate.append(predicate[j])\n",
    "                conjugation.append(conjugation[j])\n",
    "                predicate2.append(predicate2[j])\n",
    "                if(quantifier[i]==\"Universal\"==quantifier[j]):\n",
    "                    quantifier.append(\"Universal\")\n",
    "                elif(quantifier[i]==\"Existential\"==quantifier[j]):\n",
    "                    quantifier.append(\"Existential\")\n",
    "                elif((quantifier[i]==\"Universal\" and quantifier[j]==\"Existential\") or (quantifier[j]==\"Universal\" and quantifier[i]==\"Existential\")):\n",
    "                    quantifier.append(\"Existential\")\n",
    "                else:\n",
    "                    quantifier.append(\"\")\n",
    "            # Modus Tollens\n",
    "            if predicate[i]==predicate[j]:\n",
    "                if conjugation[i]==conjugation[j]==\"\":\n",
    "                    if positive[i] == True and positive[j] == False:\n",
    "                        subject.append(subject[j])\n",
    "                        positive.append(False)\n",
    "                        predicate.append(subject[i])\n",
    "                        conjugation.append(\"\")\n",
    "                        predicate2.append(\"\")\n",
    "                        if(quantifier[i]==\"Universal\"==quantifier[j]):\n",
    "                            quantifier.append(\"Universal\")\n",
    "                        elif(quantifier[i]==\"Existential\"==quantifier[j]):\n",
    "                            quantifier.append(\"Existential\")\n",
    "                        elif((quantifier[i]==\"Universal\" and quantifier[j]==\"Existential\") or (quantifier[j]==\"Universal\" and quantifier[i]==\"Existential\")):\n",
    "                            quantifier.append(\"Existential\")\n",
    "                        else:\n",
    "                            quantifier.append(\"\")\n",
    "                \n",
    "    data = {'Quantifier':quantifier,\n",
    "        'Subject':subject,\n",
    "       'Positive':positive,\n",
    "       'Predicate':predicate,\n",
    "        'And/Or':conjugation,\n",
    "       'Second Predicate':predicate2}\n",
    " \n",
    "    # Create knowledge Base\n",
    "    extendedKnowledgeBase = pd.DataFrame(data)\n",
    "    extendedKnowledgeBase.drop_duplicates(subset =['Quantifier','Subject','Positive','Predicate','And/Or','Second Predicate'], \n",
    "                     keep = 'last', inplace = True) \n",
    "    \n",
    "    q_quant, q_sub, q_pos, q_pred, q_verb = extractPremise(query)\n",
    "    for i in range (len(predicate)):\n",
    "        if subject[i]==q_sub and predicate[i]==q_pred:\n",
    "            if quantifier[i]==q_quant:\n",
    "                if positive[i]==q_pos:\n",
    "                    return(\"\\nQuery is TRUE.\")\n",
    "                else:\n",
    "                    return(\"\\nQuery is FALSE.\")\n",
    "            \n",
    "    return(\"\\nInsufficient data. Query cannot be determined as TRUE or FALSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "txt_layout = Layout(width='550px')\n",
    "premise_box = Text(description='Premise', layout=txt_layout, value=\"\")\n",
    "query_box = Text(description='Query', layout=txt_layout, value=\"\")\n",
    "\n",
    "go_btn = Button(description='GO', button_style='success', layout=Layout(width='50px'))\n",
    "\n",
    "result=\"Enter Premise and Query in the boxes above.\"\n",
    "sol_lbl = Label()\n",
    "sol_lbl.value=result\n",
    "sol_lbl.layout.width = '1000px'\n",
    "\n",
    "\n",
    "def optimize():\n",
    "    result=solvePred(premise_box.value,query_box.value)\n",
    "    sol_lbl.value=result\n",
    "    \n",
    "go_btn.on_click(lambda btn: optimize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332563f0faec487cace237e4699d4082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Premise', layout=Layout(width='550px')), Text(value='', descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([premise_box, query_box, go_btn, sol_lbl])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
